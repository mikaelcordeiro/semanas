{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semana 8 do Aceleradev DS Codenation\n",
    "\n",
    "### Professor: Kazuki Yokoyama | Tema: Modelagem e Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as sct\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balanço de sustentabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressao Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, falaremos do modelo mais simples e mais usado de predição. Trazendo os significados de conceitos importantes sobre o tema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![regressoes](https://cdn-images-1.medium.com/max/800/1*_7OPgojau8hkiPUiHoGK_w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo de cara, já temos 3 resultados possíveis que um modelo de regressão pode gerar. Esses resultados tem relação com *Trade-Off* e *Viés-Variância*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade-Off Viés-Variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro cometido por um modelo pode ser dividido em 3 partes:\n",
    "\n",
    "$$\\mathbb{E}[(f(x) - \\hat{f}(x))^{2}] = \\underbrace{\\text{Bias}(\\hat{f}(x))^{2}}_{\\text{viés}} + \\underbrace{\\text{Var}[\\hat{f}(x)]}_{\\text{variância}} + \\underbrace{\\varepsilon^{2}}_{\\text{erro irredutível}}$$\n",
    "\n",
    "- Viés: conceitualmente, é a diferença entre o previsto e o valor correto que estamos prever. Podemos introduzir um viés na regressão através da escolha do modelo. Quando temos um *dataset* não linear, mas usamos uma regressão linear para tentar predizer algo sobre ele, estamos introduzindo um viés ao modelo. No caso, esse viés é a **simplicidade do modelo perante a complexidade dos dados**. Ou seja, o algoritmo *não apendem* muito bem, não capta as variações legítimas dos dados, gerando um **Underfitting**. São exemplos de **modelos com alto viés:** regressão linear, regressão logística, e são exemplos de **baixo viés:** árvores de decisão, kNN e SVM(Support Vector Machines)\n",
    "\n",
    "- Variância: conceitualmete, representa quanto os valores previstos variam frente frente as repetições das predições através de dados diferentes. Essa é o oposto do viés. Ocorre quando usamos **um modelo muito complexo em um *dataset* com linearidade alta**. O resultado se parece muito com uma interpolação de grau $n-1$, sendo n o número de pontos. Nesse cenário, o modelo gera um **Overfitting**. Parece que os algorítmos *decoraram* os dados de treino, obtendo um *superaprendizado*, **ele não aprende a generalizar**. Reflexo disso é o *fit* gerado apresentar baixa variação nos dados de treino e alta variação nos dados de teste. São exemplos de **modelos com baixa variância:** regressão linear, regressão logística, e são exemplos de **alta variância:** árvores de decisão, kNN e SVM(Support Vector Machines)\n",
    "\n",
    "- erro irreditível: é o erro inerente à regressão linear. Não tem como mitigá-lo.\n",
    "\n",
    "Eu creio que foi possível perceber que o viés e a variância são antagônicos: se vc aumenta um, diminui o outro (por isso se chama *trade-off*). E visto como um modelo se equilibra nessas 3 partes. O que fazemos? Nesse equilíbrio entre viés/variância, podemos ter 2 cenários críticos:\n",
    "\n",
    "- modelo com baixa flexibilidade: ocorre quando o **viés está alto, mas a variância está baixa**. Nesse cenário, **o modelo erra muito quando são *inputados* os dados de teste** devido ao *underfitting*,\n",
    "\n",
    "- modelo com alta flexibilidade: ocorre quando o **viés está baixo, mas a variância está alta**. Aí entramos no estágio de *overfitting*, onde o modelo começa a errar bastante com os dados de teste.\n",
    "\n",
    "Como eu dei ênfase nos dados de teste, deu pra perceber que é nesse momento que avaliamos se um modelo está bom ou não, é o erro nessa fase que conta, pois é nessa hora que o modelo treinado encara valores que ele não conhece, e a idéia de *treinamento* é justamente essa: ter uma boa performance com dados que o modelo não conhece. E a chave é encontrar o equilíbrio entre viés/variância, para que o modelo erre o dentro do aceitável de erro (cada problema tem sua régua de erro).\n",
    "\n",
    "**Resumindo:** o viés está relacionado à falha do modelo em aprender com os dados de treino, enquanto a variância está relacionada à falha em prever através dos dados de teste. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regressão Linear (OLS - Ordinary Least Squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo do modelo:** previsão de uma variável **dependente** através de variáveis **independentes**. Vale ressaltar que, embora se chame regressão linear, não são apenas retas que o modelo gera, ele é capaz de gerar *fit*  não lineares também, como um polinômio por exemplo.\n",
    "\n",
    "**Modelo Teórico Simples:** Para enterdermos, vamos começar com um problema de regressão de apenas uma variável independente. Podemos escrever que o valor esperado da variável independente $Y$ para um dado $X_i$ de $X$ é:\n",
    "\n",
    "$$\\mathbb{E}(Y|X_i)=f(X_i)$$\n",
    "\n",
    "Tomando que $f(X)$ é **linear**, temos:\n",
    "\n",
    "$$f(X)=\\beta_0+\\beta_1X \\text{, sendo chamada de FRP(Função de Regressão Populacional)}$$\n",
    "\n",
    "Como de praxe, para um dado valor de $X$, existe um valor de $Y$. Assim, para não trabalharmos com o valor populacional, devemos introduzir um erro à equação caso usemos uma amostra:\n",
    "\n",
    "$$y_i=f(X_i)=\\beta_0+\\beta_1X_i+e_i \\text{, sendo chamada de FRA(Função de Regressão Amostral)}$$\n",
    "\n",
    "E o erro $e_i$ relaciona-se com $Y_i$ através de $y_i$ da seguinte maneira:\n",
    "\n",
    "$$e_i=Y_i-y_i$$\n",
    "\n",
    "Imagine que temos várias observações de $X$. Portanto, teremos vários pares ordenados $(X_i,Y_i)$. Como usamos sempre amostras para treinar modelos, quando essa equação encontra dados de teste, sempre terá um erro $\\epsilon_i$ associado a cada valor. Podemos escrever esse erro da seguinte maneira:\n",
    "\n",
    "$$\\text{RSS} = \\sum_{1 \\leq i \\leq n} e_{i}^{2} = \\sum_{1 \\leq i \\leq n} (Y_{i} - {y}_{i})^{2}\\text{, sendo Residual Sum of Squares}$$\n",
    "\n",
    "No caso da regressão, procura-se por uma curva que **minimize** o MSE(Mean Square Error):\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{1 \\leq i \\leq n} e_{i}^{2} = \\frac{1}{n} \\sum_{1 \\leq i \\leq n} (Y_{i} - {y}_{i})^{2}$$\n",
    "\n",
    "ou seja:\n",
    "\n",
    "$$\\underset{\\hat{\\beta}_{0}, \\hat{\\beta}_{2}, \\cdots, \\hat{\\beta}_{p}}{\\text{minimizar}} \\text{MSE} = \\frac{1}{n} \\sum_{1 \\leq i \\leq n} (Y_{i} - \\hat{\\beta}_{0} - \\sum_{1 \\leq j \\leq p} \\hat{\\beta}_{j}x_{ij})^{2}$$\n",
    "\n",
    "E para avaliar o nosso modelo após treiná-lo, temos o RMSE(Root Mean Square Error):\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{1 \\leq i \\leq n} e_{i}^{2} = \\sum_{1 \\leq i \\leq n} (Y_{i} - {y}_{i})^{2}}$$\n",
    "\n",
    "Para ilustrar:\n",
    "\n",
    "![residual](https://uc-r.github.io/public/images/analytics/regression/sq.errors-1.png)\n",
    "\n",
    "*Repare:* os pontos **vermelhos** representam as posições reais dos pontos de teste, as retas **pretas** representam o MSE, e a **linha azul** representa o lugar geométrico onde MSE é mínimo.\n",
    "\n",
    "**Modelo Teórico Geral:** podemos extrapolar essa idéia para um problema de várias variáveis agora. Vamos imaginar uma mesmo variável dependente $Y$ que se relaciona **linearmente** com as variáveis independentes de $\\Omega=[X_1,X_2, \\dots, X_p]$. Então, podemos escrever $Y$ como uma **combinação linear** de $\\Omega$:\n",
    "\n",
    "$$Y(X_1,X_2,\\dots,X_p)=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\dots+\\beta_pX_p$$\n",
    "\n",
    "*Nota:* perceba que cada $X_p$ tem seu conjunto de valores, ou seja: cada um é uma *feature*\n",
    "\n",
    "**Pontos Fracos da OLS**\n",
    "\n",
    "Esse tipo de regressão possui uma sensitividade alta à **outliers** e **multicolinearidade**, tendendo ao **Overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prática em Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos importar o *dataset* Boston house prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = boston_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  TARGET  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features, columns=boston_dataset.feature_names).join(pd.Series(target, name='TARGET')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separando dados para treino e teste**\n",
    "\n",
    "para fazer isso, usamos uma função do `sklearn.model_selection`\n",
    "\n",
    "```python\n",
    "sklearn.model_selection.train_test_split(*arrays, test_size=, random_state=)\n",
    "```\n",
    "*Parâmetros:*\n",
    "\n",
    "- arrays: aqui vc coloca X com as *features* e Y com o *target*\n",
    "- test_size:\n",
    "    - int: representa o número absoluto de amostras de teste\n",
    "    - float: valor dentro de [0,1] que representa a proporção dos dados que vai ser usada para teste\n",
    "- random_state: int que representa alguma coisa de embaralhamento dos dados\n",
    "\n",
    "*O que retorna:*\n",
    "\n",
    "retorna uma lista de arrays na seguinte ordem: x_treino, x_teste, y_treino, y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_teste, y_treino, y_teste = train_test_split(boston_dataset.data, boston_dataset.target, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treinamento do modelo de regressão linear**\n",
    "\n",
    "Vamos treinar com todas as *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo linear foi treinado de acordo com as *features* de treino e *target*. **NÃO SE TREINA UM MODELO COM DADOS DE TESTE**\n",
    "\n",
    "Podemos resgatar algumas informações interessantes como:\n",
    "\n",
    "Coeficientes $\\beta_1, \\beta_2, \\dots, \\beta_{13}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.13055924e-01,  3.01104641e-02,  4.03807204e-02,  2.78443820e+00,\n",
       "       -1.72026334e+01,  4.43883520e+00, -6.29636221e-03, -1.44786537e+00,\n",
       "        2.62429736e-01, -1.06467863e-02, -9.15456240e-01,  1.23513347e-02,\n",
       "       -5.08571424e-01])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Termo independente $\\beta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.246750993923513"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prevendo valores do *target* através dos dados de teste**\n",
    "\n",
    "Agora usamos nossos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsto = regressor.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.99672362, 36.02556534, 14.81694405, 25.03197915, 18.76987992])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsto[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparando com os valores esperados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.6, 32.4, 13.6, 22.8, 16.1])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "percebe-se que não estão muito parecidos. Embora seja possível constatar visualmente que o predito não está bom, podemos usar as medidas de erro aprendidas nesse notebook\n",
    "\n",
    "**MSE - Mean Squared Error**\n",
    "\n",
    "Seu valor é sempre não negativo, e considera a **Média** dos erros. Como toda média, sofre com valores extremos. Ou seja, se você não tratou os *outliers* antes, essa medida será afetada. Quanto mais próximo do zero, melhor é a performance do modelo. Entretanto, seu valor sozinho só serve para **comparar modelos**, caso você gere modelos diferentes, ou o mesmo modelo, mas com *features* diferentes, usar o MSE é uma boa para dizer que modelo está melhor que o outro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.291119474973588"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true=y_teste, y_pred=previsto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MedSE - Median Squared Error**\n",
    "\n",
    "Seu valor pode assumir qualquer valor Real. Essa medida de erro busca a **Mediana** dos erros de cada ponto, e é mais resistente aos *outliers*. Tal qual o MSE, seu valor sozinho é bom para comparação entre de modelos de regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.32433190641245"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error(y_true=y_teste, y_pred=previsto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coeficiente de Determinação $R^2$**\n",
    "\n",
    "Valor compreendido no intervalo [0,1]. Sua maneira de interpretar é simples: seu resultado reflete a proporção dos valores que o modelo consegue explicar.\n",
    "\n",
    "*Nota*: se for usar essa medida para comparar modelos diferentes, certifique-se que eles foram treinados com o mesmo número de variáveis, pois essa métrica aumenta seu valor à medida que se aumenta o número de features, ai não dá pra saber se, de fato, um modelo explica mais sobre os dados porque é bom ou porque tem mais variáveis\n",
    "\n",
    "*Nota 2*: o $R^2$ pode apresentar valores negativos se não tiver o intercepto incluso no modelo. Caso isso aconteça, repare na classe LinearRegression() se o parâmetro do intercepto está *setado*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668759493535631"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_true=y_teste, y_pred=previsto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, esse modelo explica 66,88% da variação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modo gráfico**\n",
    "\n",
    "Visualmente, podemos perceber se escolhemos boas variáveis para o modelo aprender sobre o `Target`, basta confrontar os valores do `Target` de teste com os valores previstos através do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_teste, previsto, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível perceber que existe uma linearidade, e que a falta de tratamento dos *outliers*, bem como a não padronização/normalização dos dados, está derrubando a performance do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prevendo o valor de uma tupla**\n",
    "\n",
    "Só para segmentar, o valor previsto do *target* é descrito como a combinação linear das variáveis escolhidas para o modelo. E nesse processo de treino, obteve-se um array de coeficientes $\\beta_1, \\beta_2, \\dots, \\beta_{13}$. Repare: podemos decompor a equação da combinação linear numa multiplicação de matrizes. Veja:\n",
    "\n",
    "$$target(X_1,\\dots,X_{13})=\\beta_0+\\beta_1X_1+\\dots+\\beta_{13}X_{13}=\\beta_0+\\begin{bmatrix}X_1& \\dots& X_{13}\\end{bmatrix}\\begin{bmatrix}\\beta_1\\\\ \\vdots \\\\ \\beta_{13}\\end{bmatrix}$$\n",
    "\n",
    "Assim, se eu quiser saber o valor de previsão de uma tupla, basta eu fazer um **produto escalar** entre o vetor da tupla e o dos coeficientes, e depois somar ao valor do intercepto. Então, vamos descobrir o valor do `Target` da primera tupla do *set* de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.969524053507278"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_0 = regressor.intercept_\n",
    "target_tupla_000 = beta_0 + x_treino[0, :].dot(regressor.coef_)\n",
    "target_tupla_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressões Lineares Regularizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regressão Linear Ridge**\n",
    "\n",
    "$$J^{\\text{ridge}}(\\hat{\\beta}) = \\frac{1}{n} \\sum_{1 \\leq i \\leq n} (y_{i} - \\hat{\\beta}_{0} - \\sum_{1 \\leq j \\leq p} \\hat{\\beta}_{j}x_{ij})^{2} + \\underbrace{\\lambda \\sum_{1 \\leq j \\leq p} \\hat{\\beta}_{j}^{2}}_{\\text{termo de regularização}}$$\n",
    "\n",
    "Para $\\lambda=0$, temos a já vista MSE que obtém os parâmetros $\\beta_1, \\dots, \\beta_p$. Perceba também que a porção de regularização começa em 1, justamente para não regularizar o intercepto $\\beta_0$.\n",
    "\n",
    "Graficamente, podemos ver como o hiperparâmetro de regularização $\\lambda$ influencia o MSE:\n",
    "\n",
    "![mse-lambda](https://drive.google.com/uc?export=download&id=196MmaQswPNPhBt46zttNJbffFny3bBGH)\n",
    "\n",
    "**curva preta:** representa a viés\n",
    "\n",
    "**curva verde:** representa o variânia\n",
    "\n",
    "**curva rosa:** representa a MSE\n",
    "\n",
    "**linha tracejada:** representa o erro irredutível\n",
    "\n",
    "Esse gráfico demonstra o *trade-off*, partindo de um estado de **Overfitting** (alta variância e baixo viés), para um de **Underfitting** (baixa variância e alto viés). Percebe-se que, no início, a taxa de queda da variância é mais acentuada que a taxa de crescimento do viés. Entretanto, a partir do valor do hiperparâmetro $\\lambda$, o viés tem taxa de crescimento alta e taxa de queda baixa. Encontrar o valor do hiperparâmetro é o que nos dá os valores dos coeficientes $\\beta_1, \\dots, \\beta_p$ que **minimizam a MSE**. E para obter o valor do $\\lambda$ que leva à essa situação, fazermos *cross-validarion*\n",
    "\n",
    "A regressão Ridge é muito resistente à covariância, pois lida muito bem com a alta variância.\n",
    "\n",
    "**Nota:** fazemos a **regularização apenas no momento de TREINO**, ou seja, com o *trainig set*\n",
    "\n",
    "**Nota 2:** os **dados devem estar PADRONIZADOS** no momento de treino\n",
    "\n",
    "A Regressão de Ridge também é chamada de Regressão $\\mathcal{l}_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos praticar essa regressão com o *dataset* padronizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "padronizador = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino_std = padronizador.fit_transform(x_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_std = padronizador.fit_transform(y_treino.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste_std = padronizador.fit_transform(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste_std = padronizador.fit_transform(y_teste.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados de treino padronizados, vamos treinar o modelo. Eu creio que `alpha` da classe `Ridge` seja o nosso $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_regressor = Ridge(alpha=1, solver='cholesky', fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, solver='cholesky')"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regressor.fit(x_treino_std, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coeficientes e o intercepto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99218679,  0.6777488 ,  0.2522143 ,  0.72248078, -1.99083465,\n",
       "        3.15157218, -0.17726162, -3.04502895,  2.17324941, -1.69555879,\n",
       "       -2.02783351,  1.127197  , -3.59897667])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.796534653465375"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regressor.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previsão com Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsto_ridge = ridge_regressor.predict(x_teste_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos analisar os erros**\n",
    "\n",
    "*MSE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.401919702622887"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true=y_teste, y_pred=previsto_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MedSE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9686802590091013"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error(y_true=y_teste, y_pred=previsto_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*$R²$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263397506342121"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_true=y_teste, y_pred=previsto_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Modo Gráfico*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW80lEQVR4nO3df4xdZZ3H8c93fimsbBgGZBuG/phgMEJ2sZ3UIRKDuLgQGzEgCHYNm1AbEzfRoFHkD9wlu4n+4a8/mnW7xchuSgtpYSGNZCVYFkyc6tyiC5U11AmDg5VCvV00mE5n7nf/uOcOM7f3x7k/zj3nuef9SpqZe+bO3IfDzOc89/s853nM3QUACM9A2g0AALSHAAeAQBHgABAoAhwAAkWAA0Cghnr5Yueff76vX7++ly8JAMErFAqvu/sF1cd7GuDr16/XzMxML18SAIJnZnO1jlNCAYBAEeAAECgCHAACRYADQKAIcAAIFAEOAIEiwAEgQYW5onYcPKrCXLHrP7un88ABIE8Kc0Vt3TWthcWSRoYGtHvblDatG+3az6cHDgAJmZ49oYXFkkounV4saXr2RFd/PgEOAAmZmhjTyNCABk0aHhrQ1MRYV38+JRQASMimdaPavW1K07MnNDUx1tXyiUSAA0BbCnPFWMG8ad1o14O7ggAHgBYlPTgZFzVwAGhR0oOTcRHgANCiVgYnmQcOABkSd3Ay6VILAQ4AbYgzOFmr1MKNPAByK8mSRLcxDxwAIlmZ/REX88ABIJJ0SSIJSc4Dp4QCIBhJlyRCQw8cQDCSLkmEhgAHEJQkSxKhoYQCAIEiwAEgUAQ4AAQqdoCb2aCZPWtmB6LHG8zskJkdNbMHzWwkuWYCAKq10gP/nKQXVjz+uqRvufslkoqS7uhmwwAAjcUKcDMbl/QRSbuixybpGkn7oqfcL+ljSTQQAFBb3B74tyV9SVIpejwm6aS7L0aP5yVd1OW2AQAaaBrgZrZF0nF3L7TzAma23cxmzGzmtddea+dHAABqiNMDf7+kj5rZS5L2qlw6+Y6kc82sciPQuKRXan2zu+9090l3n7zgggu60GQAgBQjwN39K+4+7u7rJd0q6UfuvlXSQUkfj552u6RHE2slAOAMncwD/7KkO83sqMo18fu60yQAQBwtrYXi7k9Jeir6fFbS5u43CcifwlyRBZrQMhazAlIW2iYFyA5upQdSVmuTAiAOAhxIGZsUoF2UUICUsUkB2kWAAxmQxCYFDIz2PwIc6EMMjOYDNXCgDzEwmg8EONCHGBjNB0ooQB9iYDQfCHCgT7F7e/+jhAIAgSLAASBQBDgABIoAB4BAMYgJNLDybkZJzOpAphDgQA2FuaL2H57XvsK8FpdKGhowyUyLS9zZiOwgwIEqldvQT50uyaNjp5dcksv11p2NBDjSRg0cqFK5Db0S3iZpeNA03IU7GwtzRe04eFSFuWLX2ov8ogcOVKnchn56saTBAdPNkxfrxo3jkjqrgSe5wBQrD+YTAQ5UaXQbeifhWGuBqW6ELSsP5hcBDtSQxG3oK3v23VxgKqkLA7KPAEcQ+qFEkNQCU0ldGJB95u7Nn9Ulk5OTPjMz07PXQ38IuUTQqwtPrdfph4seysys4O6T1cfpgSPzslQiaCUUe3nhqS75hHzRQ3xMI0TmZWVzgkoofuOHv9LWXdNNpwKmuSsOO/LkAz1wZF5WNido9Z1AmrVp6uL5QIAjs6rLFWmXAFoNxTQvPFm56CFZDGIik7Jaw2VgEGlgEBNBiVuu6HWgZuGdAFBBgCOT4pQrstpLB3qlaYCb2dslPS3pbdHz97n7V81sg6S9ksYkFSR9yt0Xkmws8iNODTdL0wuBNMTpgZ+SdI27/9HMhiX92Mwel3SnpG+5+14z+66kOyT9S4JtRc40K1cw0wJ51zTAvTzK+cfo4XD0zyVdI+mT0fH7Jf2DCHD0EDMtkHexauBmNqhymeQSSTsk/VrSSXdfjJ4yL+miOt+7XdJ2SVq7dm2n7UWf6XQQkkFF5FmsAHf3JUlXmNm5kh6R9O64L+DuOyXtlMrTCNtpJPoTg5BAZ1q6ld7dT0o6KOlKSeeaWeUCMC7plS63DX0uzu3ecXewYacb5FGcWSgXSDrt7ifN7CxJ10r6uspB/nGVZ6LcLunRJBuK/tNsEDJuD52ePPIqTglljaT7ozr4gKSH3P2Amf1S0l4z+ydJz0q6L8F2og81G4SMO02Q6YTIqzizUP5H0ntrHJ+VtDmJRiE/Gg1Cxp0myHRC5BVroSDT4s5SafY81jBByFgLBUGotQJhvR1m4q5WmHSNnIsD0kKAByi0wGilF10vaKu/ds+Wy3TvgSOxQjnJGjkDqEgTAR6Y0AKjlfY2Ctrqrz3+/LHlx6dOl7T/8HzHtfR2MICKNLGlWmBC2yqrlfbW2jqtMFfU3Y88p1/85qSGBmz5a9dfvkZDAyapvK7DvsJ83Tngldkud3740q5f8LKy3RvyiR54YEKbcRF3WdhKiWXltEJJum3nT7SwVB5oHx40fWLzWt20cVyb1o3qyG//Tw8celkuaWmpce83qVvuWY8FaSLAAxNiYNy0cVwefaxub60Sy9TEmKZnT+iVk3/S6aW3ZkktLrkuOves5Z9x48Zx7T88n/rFjPVYkBYCPEChBEZ1ON+0cfyM51SXWPYfntfDh+e1sFjS0OCABgekxVL5udUhHeLFDOgmAhxdtbIcEmeAr7rEYtLy9ywtlXTr5rVySaZyj1uSdhw8WnOaIZBFSc4aI8DRNbWm+jVb62R69oTu2XKZim8uLH99ZVnkxhVll9Bm4ABJ/84S4GhLrV5FdY+7+OZC3RJHo1/set/DlD2EJunfWQIcsawMbEk1w7fWjJN6JY5Gv9j1vie0GThA0r+zBDiaqu4t37hxvGb4tjKo2M4vNoOWCE3Sv7MEOJqq7i2btCp8R88eOWNgsVqtdUuqf7HjDPYwaInQJPk7S4CjqZW95cHBAbm0PPA4evZI0zVJ6tW7qxeqYoASaA230qOpSm/51s1rJXft/enLuvfAEU1NjKn45kLTW+Xr3U6/chu0dpcIYCs15Bk9cMSyad2opmdPaLHkq0K2US37gUMv6/Hnj+myNX9+xnNanXJYC7125B0Bjrqqa9L1ZpnUGqR54NDLuvuR5yRJz7z4uj7zgQmdc9bw8nN2HDwae8phPUwrRN4R4KipXu+2erGpyuDlZz94yarvf/z5Y6seHzn2hv7jjvctP25lymE9TCtE3hHgqKle77byr1n54vrL1+iZF19f9XilbkyvYloh8o4AR03NereNyheFuaKKby7oMx+Y0JFjb+j6y9fok+9be8ZrdGN6FdMKkWcEeA60s5hOs97t6NkjGjCT5KsCvjBX1G3/Nr0c/Hs+zcAikBQCvM+1O1OjUegX5oq698ARLZVcgwOme7ZctvycylKwUnlVwYcbbHXWymsCOBMBnrKkQ6udmRrNQr/yM12Su6v45sLy17zqZ1U/bvc1CXfgTNzIk6JKaH3jh7/S1l3TidyMsnLPxsEB029P/qnp6zS7qWZqYkxDg+W1uwcHV9fHb9o4rpFBK99uP2g1N3Fo9TV7cZ6AEBHgKerFBsWVWvYnNq+VzLTnpy83DcF6G/VWNhj+1//+tUqlaJscX93H3rRuVHu2X6kv/s2l2rP9yti95UabA4e2kTPQK5RQUtSreczLd1EuxSul1FtoauUGwxVLJT/jZ7UzM6TRoCnzvYHaCPAU9XIec6u7w6/cpKHy8XRVeJvO7C13ol7wM98bqI0AT1mv5jE3C8GVg4gDZtp21QZ9/ycvrVqrZHjQlnvgw4OmmycvrrnTfFLtJ7iB1ZoGuJldLOnfJV2o8qSCne7+HTM7T9KDktZLeknSLe7O6FJG1OpNNwrBlXXmkrt2PjMr9/L/8MpaJXu2X6n9h+eXNxgmUIF0xemBL0r6grsfNrNzJBXM7AlJfyfpSXf/mpndJekuSV9OrqnZlaUpboW5ovYfnte+wrwWl+LP/Z6aGNOAmUrRoGTJpaEBk7u3vVYJgGQ1DXB3PybpWPT5H8zsBUkXSbpB0tXR0+6X9JRyGOBZWtK00pZTp0vL86/jzv3etG5U267aoO8+Pbt8bNtVG1atIAggW1qqgZvZeknvlXRI0oVRuEvS71QusdT6nu2StkvS2rVnrocRuiwtabryBhsp3iDjyncP55w1rAEr974HTDrnrOEzVhkEkB2xA9zM3iFpv6TPu/sbZrb8NXd3M6t5052775S0U5ImJyfj3pgXjCxNcVu19dlAeZCxUa26lU0VslQmAlAWK8DNbFjl8N7t7g9Hh181szXufszM1kg6nlQjsyzJKW6thmarbal+91BvU4UslYkAvCXOLBSTdJ+kF9z9myu+9Jik2yV9Lfr4aCItDEASg3vtruoXpy2VC8Po2SOxNlWodyckPXIgXXF64O+X9ClJz5nZz6Njd6sc3A+Z2R2S5iTdkkwT86mTVf0aqVU2Kb650DCIq8tEo2eP1O2RU2oBeifOLJQfqzweVsuHutscVLS7ql8ztcomzQYqq0sz9QZuKbUAvcViVhnVaFW/wlxROw4ebWtVvkaLRtVSeS1J+uwHL1m1uXH1z2DRKaC3uJU+oyqr+nV7QLGVgc56r1XvZ2RpRg6QBwR4hjUbUDx1uqT9LdbGW6lRN5rjXqttLDoF9BYBHpipiTENDZQXlXJJ+wrzsReUarX33k6Pmtvtgd6hBp5BjWrcm9aN6ubJi5dHlZeW4teaW61RV3rUd3740rph30k9HkBn6IFnSNyFqG7cOK79h+dbrjV3u0fNrBMgXQR4RrSyEFW7teZN60Z1z5bL9Pjzx3T95Ws6DtssrQMD5BEBnhGtLkTVTq25MFfUvQeOaGGxpJ+99Htd+hfndBS4tW7w2XHwKAOYQI8Q4BlRvRDV1Ze+U+ef87YzntfJnY7d7jGvfCcwevbI8sWBcgrQGwR4RtQLw4cPzy+HYac1527M066+gFT+7Th4lHIK0GMEeMpqBWK9MOy0B93pPO1GFxBu4gF6jwBPUb1ArBeG3QjJTuZpN7uxh5t4gN4iwJtIcnW9eoFYLwzTDslmFxBu4gF6iwBvIOl5zo0CsV4YdhqSnVyQ0r6AAFiNAG8g6XnOvQ7EOBekZgFPLxvIDgK8gV4MzPUyEJtdkLizEggLAd5Av5UMml2QuLMSCAsB3kQ/lQyaXZCYCgiExdy7tVlXc5OTkz4zM9Oz10Pr2NMSyB4zK7j7ZPVxeuBYpZ/ecQD9jvXAU8Aa2tnC/w+Eih54jxXmirrt36aX68x7Ps1MjzQx8wYhowfeYw8fnl9eNrayWBXS0+ouRUCWEOAdavXtd/WQce+GkFFLZebNoDVefx3IIkooHWjn7fdNG8e1b+Y3Or3kGh403bRxvEetRS39Ntcf+UKAd6CdG182rRvVnu1XEhgZwswbhIoA70C7N74QGAC6gQDvAG+/AaSprwO8F3cV0psGkJamAW5m35O0RdJxd788OnaepAclrZf0kqRb3D1Td0EwvxdAv4szjfD7kq6rOnaXpCfd/V2SnoweZ0o35/dypx6ALGraA3f3p81sfdXhGyRdHX1+v6SnJH25i+3qWLdW1qMnDyCr2q2BX+jux6LPfyfpwnpPNLPtkrZL0tq1a9t8udZ1a4CRNbIBZFXHg5ju7mZW94ZCd98paadUXk6209drRTcGGFkjG0BWtRvgr5rZGnc/ZmZrJB3vZqOyhKmCALKq3QB/TNLtkr4WfXy0ay3KIKYKAsiiprNQzGyPpJ9IutTM5s3sDpWD+1oze1HSX0ePAQA9FGcWym11vvShLrcFANAClpMFgEAR4AAQKAIcAAJFgANAoAhwAAhUEAHOYlIAcKbMrweetcWkerHGOADEkfkAz9JiUisvJkMDppsnL9aNG8cJcgCpyHwJpbKY1KAp9cWkVl5MFpZcDxx6WVt3TVPaAZCKzPfAs7SYVOVicup0SS7Jlf67AgD5lfkAl7KzmFTlYrL/8Lz2Fea1tMQSswDSE0SAZ0nlYnLTxvFMvCsAkF8EeJuy8q4AQH5lfhATAFAbAQ4AgSLAASBQBDgABIoAB4BAEeAAECgCHAACRYADQKAIcAAIFAEOAIEiwAEgUAQ4AASKAAeAQBHgABAoAhwAAkWAA0CgOgpwM7vOzH5lZkfN7K5uNQq9U5grasfBo2zMDASo7R15zGxQ0g5J10qal/QzM3vM3X/ZrcYhWYW5orbumtbCYkkjQwPavW2KXYaAgHTSA98s6ai7z7r7gqS9km7oTrPQC9OzJ7SwWFLJpdOLJU3Pnki7SQBa0EmAXyTpNysez0fHVjGz7WY2Y2Yzr732Wgcvh26bmhjTyNCABk0aHhrQ1MRY2k0C0ILENzV2952SdkrS5OSkJ/16iG/TulHt3jal6dkTmpoYo3wCBKaTAH9F0sUrHo9HxxCQTetGCW4gUJ2UUH4m6V1mtsHMRiTdKumx7jQLANBM2z1wd180s7+X9F+SBiV9z92PdK1lAICGOqqBu/sPJP2gS20BALSAOzEBIFAEOAAEigAHgEAR4AAQKAIcAAJFgANAoAhwAAgUAQ4AgSLAASBQBDgABIoAB4BAEeAAECgCHAACRYADQKAIcAAIFAEOAIHq6wAvzBW14+BRFeaKaTcFALou8V3p01KYK2rrrmktLJY0MjSg3dum2LwXQF/p2x749OwJLSyWVHLp9GJJ07Mn0m4SAHRV3wb41MSYRoYGNGjS8NCApibG0m4SAHRV35ZQNq0b1e5tU5qePaGpiTHKJwD6Tt8GuFQOcYIbQL/q2xIKAPQ7AhwAAkWAA0CgCHAACBQBDgCBIsABIFDm7r17MbPXJM317AWTcb6k19NuREZwLlbjfKzG+XhLp+dinbtfUH2wpwHeD8xsxt0n025HFnAuVuN8rMb5eEtS54ISCgAEigAHgEAR4K3bmXYDMoRzsRrnYzXOx1sSORfUwAEgUPTAASBQBDgABIoAb8DMvmdmx83s+RXHzjOzJ8zsxehjLtarNbOLzeygmf3SzI6Y2eei43k9H283s5+a2S+i8/GP0fENZnbIzI6a2YNmNpJ2W3vFzAbN7FkzOxA9zvO5eMnMnjOzn5vZTHSs638rBHhj35d0XdWxuyQ96e7vkvRk9DgPFiV9wd3fI2lK0mfN7D3K7/k4Jekad/8rSVdIus7MpiR9XdK33P0SSUVJd6TYxl77nKQXVjzO87mQpA+6+xUr5n93/W+FAG/A3Z+W9PuqwzdIuj/6/H5JH+tpo1Li7sfc/XD0+R9U/kO9SPk9H+7uf4weDkf/XNI1kvZFx3NzPsxsXNJHJO2KHptyei4a6PrfCgHeugvd/Vj0+e8kXZhmY9JgZuslvVfSIeX4fEQlg59LOi7pCUm/lnTS3Rejp8yrfJHLg29L+pKkUvR4TPk9F1L5Yv5DMyuY2fboWNf/Vvp6S7WkububWa7mYZrZOyTtl/R5d3+j3NEqy9v5cPclSVeY2bmSHpH07pSblAoz2yLpuLsXzOzqtNuTEVe5+ytm9k5JT5jZ/678Yrf+VuiBt+5VM1sjSdHH4ym3p2fMbFjl8N7t7g9Hh3N7Pirc/aSkg5KulHSumVU6RuOSXkmtYb3zfkkfNbOXJO1VuXTyHeXzXEiS3P2V6ONxlS/um5XA3woB3rrHJN0efX67pEdTbEvPRDXN+yS94O7fXPGlvJ6PC6Ket8zsLEnXqjwucFDSx6On5eJ8uPtX3H3c3ddLulXSj9x9q3J4LiTJzP7MzM6pfC7pw5KeVwJ/K9yJ2YCZ7ZF0tcpLQb4q6auS/lPSQ5LWqrw07i3uXj3Q2XfM7CpJz0h6Tm/VOe9WuQ6ex/PxlyoPRA2q3BF6yN3vNbMJlXuh50l6VtLfuvup9FraW1EJ5YvuviWv5yL6734kejgk6QF3/2czG1OX/1YIcAAIFCUUAAgUAQ4AgSLAASBQBDgABIoAB4BAEeAAECgCHAAC9f/JYmB3x+hBWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_teste, previsto_ridge, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Podemos comparar tabularmente também*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_ridge</th>\n",
       "      <th>target_regressao</th>\n",
       "      <th>target_teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.327134</td>\n",
       "      <td>28.996724</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.353747</td>\n",
       "      <td>36.025565</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.662772</td>\n",
       "      <td>14.816944</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.578092</td>\n",
       "      <td>25.031979</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.920463</td>\n",
       "      <td>18.769880</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.175862</td>\n",
       "      <td>23.254429</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.393308</td>\n",
       "      <td>17.662538</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.794558</td>\n",
       "      <td>14.341190</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_ridge  target_regressao  target_teste\n",
       "0     31.327134         28.996724          23.6\n",
       "1     38.353747         36.025565          32.4\n",
       "2     16.662772         14.816944          13.6\n",
       "3     26.578092         25.031979          22.8\n",
       "4     19.920463         18.769880          16.1\n",
       "5     25.175862         23.254429          20.0\n",
       "6     19.393308         17.662538          17.8\n",
       "7     15.794558         14.341190          14.0"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'target_ridge': previsto_ridge.flatten(), 'target_regressao': previsto, 'target_teste': y_teste}).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regressão Linear Lasso**\n",
    "\n",
    "LASSO (Least Absolute Shrinkage and Selection Operator) é uma outra maneira de regularizar **MSE**\n",
    "\n",
    "$$J^{\\text{LASSO}}(\\hat{\\beta}) = \\frac{1}{n} \\sum_{1 \\leq i \\leq n} (y_{i} - \\hat{\\beta}_{0} - \\sum_{1 \\leq j \\leq p} \\hat{\\beta}_{j}x_{ij})^{2} + \\underbrace{\\lambda \\sum_{1 \\leq j \\leq p} \\| \\hat{\\beta}_{j} \\|}_{\\text{termo de regularização}}$$\n",
    "\n",
    "Perceba que o termo de regularização é um pouco diferente, mas não modifica o intercepto. E essa diferença é sufuciente para fazer essa regressão ter um comportamento muito peculiar: ser capaz de zerar os coeficientes $\\beta_1, \\dots, \\beta_p$ que possuiem pouca relevância, como se fosse uma seleção de *features* embutida nesse modelo de regressão\n",
    "\n",
    "**Nota:** fazemos a **regularização apenas no momento de TREINO**, ou seja, com o *trainig set*\n",
    "\n",
    "**Nota 2:** os **dados devem estar PADRONIZADOS** no momento de treino\n",
    "\n",
    "A Regressão de Ridge também é chamada de Regressão $\\mathcal{l}_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_regressor = Lasso(alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.5)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_regressor.fit(x_treino_std, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coeficientes e intercepto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.79653465346538"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30737992,  0.        , -0.        ,  0.40396576, -0.        ,\n",
       "        3.32512039, -0.        , -0.3333949 , -0.        , -0.        ,\n",
       "       -1.46416614,  0.80194371, -3.53546088])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_regressor.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previsão com Lasso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsto_lasso = lasso_regressor.predict(x_teste_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise de Erros**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MSE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.887699514722406"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true=y_teste, y_pred=previsto_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MedSE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9165732440979752"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error(y_true=y_teste, y_pred=previsto_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*$R^2$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060792411109097"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_true=y_teste, y_pred=previsto_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*$R^2$ ajustado para k = 8 (7 features + 1 intercepto)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5721935844322783"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (1 - r2_score(y_true=y_teste, y_pred=previsto_lasso)) * (y_teste.size - 1) / (y_teste.size - (8 + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Graficamente*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_teste, previsto_lasso, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tabularmente*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_ridge</th>\n",
       "      <th>target_lasso</th>\n",
       "      <th>target_regressao</th>\n",
       "      <th>target_teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.327134</td>\n",
       "      <td>28.753071</td>\n",
       "      <td>28.996724</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.353747</td>\n",
       "      <td>33.851945</td>\n",
       "      <td>36.025565</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.662772</td>\n",
       "      <td>19.365964</td>\n",
       "      <td>14.816944</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.578092</td>\n",
       "      <td>26.106978</td>\n",
       "      <td>25.031979</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.920463</td>\n",
       "      <td>20.922822</td>\n",
       "      <td>18.769880</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.175862</td>\n",
       "      <td>24.481583</td>\n",
       "      <td>23.254429</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.393308</td>\n",
       "      <td>19.921782</td>\n",
       "      <td>17.662538</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.794558</td>\n",
       "      <td>16.458811</td>\n",
       "      <td>14.341190</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_ridge  target_lasso  target_regressao  target_teste\n",
       "0     31.327134     28.753071         28.996724          23.6\n",
       "1     38.353747     33.851945         36.025565          32.4\n",
       "2     16.662772     19.365964         14.816944          13.6\n",
       "3     26.578092     26.106978         25.031979          22.8\n",
       "4     19.920463     20.922822         18.769880          16.1\n",
       "5     25.175862     24.481583         23.254429          20.0\n",
       "6     19.393308     19.921782         17.662538          17.8\n",
       "7     15.794558     16.458811         14.341190          14.0"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'target_ridge': previsto_ridge.flatten(), 'target_lasso': previsto_lasso.flatten(), 'target_regressao': previsto, 'target_teste': y_teste}).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perceba:** os valores de validação de erro para Lasso e Ridge foram bem parecidos. Entretanto, como na regressão Lasso 6 variáveis tiveram seus coeficientes zerados, pode-se perceber que conseguimos ter uma mesma performance com menos *features*.\n",
    "\n",
    "**Nota:** Não tratamos os *outliers*, essas regressões faziam parte do objetivo de entender a teoria e aplicação dela"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
