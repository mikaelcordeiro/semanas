{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semana 8 do Aceleradev DS Codenation\n",
    "\n",
    "### Professor: Kazuki Yokoyama | Tema: Modelagem e Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as sct\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressao Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, falaremos do modelo mais simples e mais usado de predição. Trazendo os significados de conceitos importantes sobre o tema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![regressoes](https://cdn-images-1.medium.com/max/800/1*_7OPgojau8hkiPUiHoGK_w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo de cara, já temos 3 resultados possíveis que um modelo de regressão pode gerar. Esses resultados tem relação com *Trade-Off* e *Viés-Variância*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade-Off Viés-Variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro cometido por um modelo pode ser dividido em 3 partes:\n",
    "\n",
    "$$\\mathbb{E}[(f(x) - \\hat{f}(x))^{2}] = \\underbrace{\\text{Bias}(\\hat{f}(x))^{2}}_{\\text{viés}} + \\underbrace{\\text{Var}[\\hat{f}(x)]}_{\\text{variância}} + \\underbrace{\\varepsilon^{2}}_{\\text{erro irredutível}}$$\n",
    "\n",
    "- Viés: esse vem da escolha do modelo. Quando temos um *dataset* não linear, mas usamos uma regressão linear para tentar predizer algo sobre ele, estamos introduzindo um viés ao modelo. No caso, esse viés é a **simplicidade do modelo perante a complexidade dos dados**. Ou seja, o algoritmo *não apendem* muito bem, não capta as variações legítimas dos dados, gerando um **Underfitting**.\n",
    "\n",
    "- Variância: essa é o oposto. Ocorre quando usamos **um modelo muito complexo em um *dataset* com linearidade baixa**. O resultado se parece muito com uma interpolação de grau $n-1$, sendo n o número de pontos. Nesse cenário, o modelo gera um **Overfitting**. Parece que os algorítmos *decoraram* os dados de treino, obtendo um *superaprendizado*, **ele não aprende a generalizar**. Reflexo disso é o *fit* gerado apresentar baixa variação nos dados de treino e alta variação nos dados de teste.\n",
    "\n",
    "- erro irreditível: é o erro inerente à regressão linear. Não tem como mitigá-lo.\n",
    "\n",
    "Eu creio que foi possível perceber que o viés e a variância são antagônicos: se vc aumenta um, diminui o outro (por isso se chama *trade-off*). E visto como um modelo se equilibra nessas 3 partes. O que fazemos? Nesse equilíbrio entre viés/variância, podemos ter 2 cenários críticos:\n",
    "\n",
    "- modelo com baixa flexibilidade: ocorre quando o **viés está alto, mas a variância está baixa**. Nesse cenário, **o modelo erra muito quando são *inputados* os dados de teste** devido ao *underfitting*,\n",
    "\n",
    "- modelo com alta flexibilidade: ocorre quando o **viés está baixo, mas a variância está alta**. Aí entramos no estágio de *overfitting*, onde o modelo começa a errar bastante com os dados de teste.\n",
    "\n",
    "Como eu dei ênfase nos dados de teste, deu pra perceber que é nesse momento que avaliamos se um modelo está bom ou não, é o erro nessa fase que conta, pois é nessa hora que o modelo treinado encara valores que ele não conhece, e a idéia de *treinamento* é justamente essa: ter uma boa performance com dados que o modelo não conhece. E a chave é encontrar o equilíbrio entre viés/variância, para que o modelo erre o dentro do aceitável de erro (cada problema tem sua régua de erro)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo do modelo:** previsão de uma variável **dependente** através de variáveis **independentes**. Vale ressaltar que, embora se chame regressão linear, não são apenas retas que o modelo gera, ele é capaz de gerar *fit*  não lineares também, como um polinômio por exemplo.\n",
    "\n",
    "**Modelo Teórico Simples:** Para enterdermos, vamos começar com um problema de regressão de apenas uma variável independente. Podemos escrever que o valor esperado da variável independente $Y$ para um dado $X_i$ de $X$ é:\n",
    "\n",
    "$$\\mathbb{E}(Y|X_i)=f(X_i)$$\n",
    "\n",
    "Tomando que $f(X)$ é **linear**, temos:\n",
    "\n",
    "$$f(X)=\\beta_0+\\beta_1X \\text{, sendo chamada de FRP(Função de Regressão Populacional)}$$\n",
    "\n",
    "Como de praxe, para um dado valor de $X$, existe um valor de $Y$. Assim, para não trabalharmos com o valor populacional, devemos introduzir um erro à equação caso usemos uma amostra:\n",
    "\n",
    "$$y_i=f(X_i)=\\beta_0+\\beta_1X_i+e_i \\text{, sendo chamada de FRA(Função de Regressão Amostral)}$$\n",
    "\n",
    "E o erro $e_i$ relaciona-se com $Y_i$ através de $y_i$ da seguinte maneira:\n",
    "\n",
    "$$e_i=Y_i-y_i$$\n",
    "\n",
    "Imagine que temos várias observações de $X$. Portanto, teremos vários pares ordenados $(X_i,Y_i)$. Como usamos sempre amostras para treinar modelos, quando essa equação encontra dados de teste, sempre terá um erro $\\epsilon_i$ associado a cada valor. Podemos escrever esse erro da seguinte maneira:\n",
    "\n",
    "$$\\text{RSS} = \\sum_{1 \\leq i \\leq n} e_{i}^{2} = \\sum_{1 \\leq i \\leq n} (Y_{i} - {y}_{i})^{2}\\text{, sendo Residual Sum of Squares}$$\n",
    "\n",
    "No caso da regressão, procura-se por uma curva que **minimize** o MSE(Mean Square Error):\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{1 \\leq i \\leq n} e_{i}^{2} = \\frac{1}{n} \\sum_{1 \\leq i \\leq n} (Y_{i} - {y}_{i})^{2}$$\n",
    "\n",
    "ou seja:\n",
    "\n",
    "$$\\underset{\\hat{\\beta}_{0}, \\hat{\\beta}_{2}, \\cdots, \\hat{\\beta}_{p}}{\\text{minimizar}} \\text{MSE} = \\frac{1}{n} \\sum_{1 \\leq i \\leq n} (Y_{i} - \\hat{\\beta}_{0} - \\sum_{1 \\leq j \\leq p} \\hat{\\beta}_{j}x_{ij})^{2}$$\n",
    "\n",
    "E para avaliar o nosso modelo após treiná-lo, temos o RMSE(Root Mean Square Error):\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{1 \\leq i \\leq n} e_{i}^{2} = \\sum_{1 \\leq i \\leq n} (Y_{i} - {y}_{i})^{2}}$$\n",
    "\n",
    "Para ilustrar:\n",
    "\n",
    "![residual](https://uc-r.github.io/public/images/analytics/regression/sq.errors-1.png)\n",
    "\n",
    "*Repare:* os pontos **vermelhos** representam as posições reais dos pontos de teste, as retas **pretas** representam o MSE, e a **linha azul** representa o lugar geométrico onde MSE é mínimo.\n",
    "\n",
    "**Modelo Teórico Geral:** podemos extrapolar essa idéia para um problema de várias variáveis agora. Vamos imaginar uma mesmo variável dependente $Y$ que se relaciona **linearmente** com as variáveis independentes de $\\Omega=[X_1,X_2, \\dots, X_p]$. Então, podemos escrever $Y$ como uma **combinação linear** de $\\Omega$:\n",
    "\n",
    "$$Y(X_1,X_2,\\dots,X_p)=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\dots+\\beta_pX_p$$\n",
    "\n",
    "*Nota:* perceba que cada $X_p$ tem seu conjunto de valores, ou seja: cada um é uma *feature*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prática em Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos importar o *dataset* Boston house prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = boston_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  TARGET  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features, columns=boston_dataset.feature_names).join(pd.Series(target, name='TARGET')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separando dados para treino e teste**\n",
    "\n",
    "para fazer isso, usamos uma função do `sklearn.model_selection`\n",
    "\n",
    "```python\n",
    "sklearn.model_selection.train_test_split(*arrays, test_size=, random_state=)\n",
    "```\n",
    "*Parâmetros:*\n",
    "\n",
    "- arrays: aqui vc coloca X com as *features* e Y com o *target*\n",
    "- test_size:\n",
    "    - int: representa o número absoluto de amostras de teste\n",
    "    - float: valor dentro de [0,1] que representa a proporção dos dados que vai ser usada para teste\n",
    "- random_state: int que representa alguma coisa de embaralhamento dos dados\n",
    "\n",
    "*O que retorna:*\n",
    "\n",
    "retorna uma lista de arrays na seguinte ordem: x_treino, x_teste, y_treino, y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_teste, y_treino, y_teste = train_test_split(boston_dataset.data, boston_dataset.target, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treinamento do modelo de regressão linear**\n",
    "\n",
    "Vamos treinar com todas as *features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo linear foi treinado de acordo com as *features* de treino e *target*. **NÃO SE TREINA UM MODELO COM DADOS DE TESTE**\n",
    "\n",
    "Podemos resgatar algumas informações interessantes como:\n",
    "\n",
    "Coeficientes $\\beta_1, \\beta_2, \\dots, \\beta_{13}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.13055924e-01,  3.01104641e-02,  4.03807204e-02,  2.78443820e+00,\n",
       "       -1.72026334e+01,  4.43883520e+00, -6.29636221e-03, -1.44786537e+00,\n",
       "        2.62429736e-01, -1.06467863e-02, -9.15456240e-01,  1.23513347e-02,\n",
       "       -5.08571424e-01])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Termo independente $\\beta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.246750993923513"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prevendo valores do *target* através dos dados de teste**\n",
    "\n",
    "Agora usamos nossos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsto = regressor.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.99672362, 36.02556534, 14.81694405, 25.03197915, 18.76987992])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsto[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparando com os valores esperados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.6, 32.4, 13.6, 22.8, 16.1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "percebe-se que não estão muito parecidos. Embora seja possível constatar visualmente que o predito não está bom, podemos usar as medidas de erro aprendidas nesse notebook\n",
    "\n",
    "**MSE - Mean Squared Error**\n",
    "\n",
    "Seu valor é sempre não negativo, e considera a **Média** dos erros. Como toda média, sofre com valores extremos. Ou seja, se você não tratou os *outliers* antes, essa medida será afetada. Quanto mais próximo do zero, melhor é a performance do modelo. Entretanto, seu valor sozinho só serve para **comparar modelos**, caso você gere modelos diferentes, ou o mesmo modelo, mas com *features* diferentes, usar o MSE é uma boa para dizer que modelo está melhor que o outro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.291119474973588"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true=y_teste, y_pred=previsto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MedSE - Median Squared Error**\n",
    "\n",
    "Seu valor pode assumir qualquer valor Real. Essa medida de erro busca a **Mediana** dos erros de cada ponto, e é mais resistente aos *outliers*. Tal qual o MSE, seu valor sozinho é bom para comparação entre de modelos de regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.32433190641245"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error(y_true=y_teste, y_pred=previsto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coeficiente de Determinação $R^2$**\n",
    "\n",
    "Valor compreendido no intervalo [0,1]. Sua maneira de interpretar é simples: seu resultado reflete a proporção dos valores que o modelo consegue explicar.\n",
    "\n",
    "*Nota*: se for usar essa medida para comparar modelos diferentes, certifique-se que eles foram treinados com o mesmo número de variáveis, pois essa métrica aumenta seu valor à medida que se aumenta o número de features, ai não dá pra saber se, de fato, um modelo explica mais sobre os dados porque é bom ou porque tem mais variáveis\n",
    "\n",
    "*Nota 2*: o $R^2$ pode apresentar valores negativos se não tiver o intercepto incluso no modelo. Caso isso aconteça, repare na classe LinearRegression() se o parâmetro do intercepto está *setado*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668759493535631"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_true=y_teste, y_pred=previsto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, esse modelo explica 66,88% da variação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modo gráfico**\n",
    "\n",
    "Visualmente, podemos perceber se escolhemos boas variáveis para o modelo aprender sobre o `Target`, basta confrontar os valores do `Target` de teste com os valores previstos através do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_teste, previsto, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível perceber que existe uma linearidade, e que a falta de tratamento dos *outliers*, bem como a não padronização/normalização dos dados, está derrubando a performance do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prevendo o valor de uma tupla**\n",
    "\n",
    "Só para segmentar, o valor previsto do *target* é descrito como a combinação linear das variáveis escolhidas para o modelo. E nesse processo de treino, obteve-se um array de coeficientes $\\beta_1, \\beta_2, \\dots, \\beta_{13}$. Repare: podemos decompor a equação da combinação linear numa multiplicação de matrizes. Veja:\n",
    "\n",
    "$$target(X_1,\\dots,X_{13})=\\beta_0+\\beta_1X_1+\\dots+\\beta_{13}X_{13}=\\beta_0+\\begin{bmatrix}\\beta_1&\\dots&\\beta_{13}\\end{bmatrix}\\begin{bmatrix}X_1\\\\ \\vdots\\\\ X_{13}\\end{bmatrix}$$\n",
    "\n",
    "Assim, se eu quiser saber o valor de previsão de uma tupla, basta eu fazer um **produto escalar** entre o vetor da tupla e o vetor de coeficientes. Então, vamos descobrir o valor do `Target` da primera tupla do *set* de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.969524053507278"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_0 = regressor.intercept_\n",
    "target_tupla_000 = beta_0 + x_treino[0, :].dot(regressor.coef_)\n",
    "target_tupla_000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
